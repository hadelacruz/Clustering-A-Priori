---
title: "Laboratorio 2"
author: "Humberto de la Cruz, Dilary Cruz, Daniel Juárez"
date: "2026-02-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r preprocesamiento, message=FALSE, echo=FALSE, warning=FALSE, results='hide'}
# =====================================================
# Carga de librerías y datos
# =====================================================
# Nota: Asegúrate de tener instalado fastDummies en tu consola, 
# no uses install.packages() dentro del Rmd.
library(dplyr)
library(tidyr)
library(stringr)
library(fastDummies)

movies <- read.csv("movies_2026.csv", header = TRUE)
movies_clean <- movies

# =====================================================
# 1. Eliminar columnas que no aportan al clustering
# =====================================================
movies_clean <- movies_clean %>%
  select(-id, -originalTitle, -title, -homePage, -actorsCharacter,
         -releaseDate, -productionCompany, -productionCompanyCountry,
         -actors, -actorsPopularity, -productionCountry, -director,
         -originalLanguage, -video, -genres )

# =====================================================
# 2. Crear variables agregadas de actorsPopularity
# =====================================================
actor_pop_list <- strsplit(movies$actorsPopularity, "\\|")

movies_clean$mean_actor_popularity <- sapply(actor_pop_list, function(x) {
  vals <- as.numeric(x)
  vals <- vals[!is.na(vals)]
  if(length(vals) == 0) return(NA)
  mean(vals)
})

movies_clean$max_actor_popularity <- sapply(actor_pop_list, function(x) {
  vals <- as.numeric(x)
  vals <- vals[!is.na(vals)]
  if(length(vals) == 0) return(NA)
  max(vals)
})

# =====================================================
# 3. Transformación logarítmica y filtros
# =====================================================
movies_clean <- movies_clean %>%
  mutate(
    budget_log  = log1p(budget),
    revenue_log = log1p(revenue)
  ) %>%
  select(-budget, -revenue) %>%
  # Es mejor filtrar anomalías ANTES de escalar
  filter(voteCount > 0, 
         voteAvg > 0, 
         budget_log > 0, 
         revenue_log > 0)


# =====================================================
# 4. Crear variables dummy para los géneros más frecuentes
# =====================================================

# Eliminar columna original de géneros
#movies_clean <- movies_clean %>% select(-genres)


# =====================================================
# 5. Limpieza de NAs y Escalamiento (Crucial)
# =====================================================
movies_clean <- na.omit(movies_clean)

# Escalar y convertir a data frame
movies_scaled <- as.data.frame(scale(movies_clean))

# Verificar resultado
dim(movies_scaled)
summary(movies_scaled)

```




## 1.2 Tendencia al Agrupamiento (Hopkins y VAT)

```{r punto-1-2, message=FALSE, warning=FALSE, echo=FALSE, fig.height=5, fig.width=5, results='hide'}
library(factoextra)
library(clustertend)

# Tomamos una muestra de 1000 observaciones para no saturar la memoria RAM
# al calcular la matriz de distancias para el VAT
set.seed(23709) 
muestra_idx <- sample(1:nrow(movies_scaled), 1000)
movies_muestra <- movies_scaled[muestra_idx, ]

# Estadístico de Hopkins
hopkins_stat <- hopkins(movies_muestra, n = nrow(movies_muestra) - 1)
cat("Estadístico de Hopkins:", hopkins_stat$H, "\n")

# Gráfica VAT
fviz_dist(dist(movies_muestra), show_labels = FALSE) +
  labs(title = "VAT - Visual Assessment of cluster Tendency")
```


```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
fviz_nbclust(
  movies_scaled,
  FUNcluster = function(x, k){
    kmeans(x, centers = k, nstart = 25, iter.max = 100)
  },
  method = "wss",
  k.max = 10
) +
labs(
  title = "Metodo del Codo para determinar k optimo",
  x = "Numero de Clusters k",
  y = "Suma de Cuadrados Intra-grupo (WSS)"
)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
k_optimo <- 2

# 1. K-Medias
set.seed(23709)
kmeans_res <- kmeans(movies_scaled, centers = k_optimo, nstart = 25)

# 2. Clustering Jerárquico (Usando la muestra por capacidad de cómputo)
matriz_distancias <- dist(movies_muestra)
hc_res <- hclust(matriz_distancias, method = "ward.D")
hc_grupos <- cutree(hc_res, k = k_optimo)

# Comparación visual (K-medias)
fviz_cluster(kmeans_res, data = movies_scaled, 
             geom = "point", ellipse.type = "convex", 
             show.clust.cent = FALSE, labelsize = 0,
             main = "Agrupamiento K-Medias")
```

```{r,message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
library(cluster)

# Silueta para K-medias (sobre una muestra representativa)
sil_kmeans <- silhouette(kmeans_res$cluster[muestra_idx], dist(movies_muestra))
fviz_silhouette(sil_kmeans, print.summary = FALSE) + 
  labs(title = "Silueta para K-Medias (k=2)")

# Silueta para Jerárquico
sil_hc <- silhouette(hc_grupos, matriz_distancias)
fviz_silhouette(sil_hc, print.summary = FALSE) + 
  labs(title = "Silueta para Jerarquico (k=2)")
```



```{r,message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Agregar el cluster de k-medias al dataset limpio original para interpretar
movies_analisis <- movies_clean %>%
  mutate(Cluster = as.factor(kmeans_res$cluster))

# Medidas de tendencia central por grupo (Variables continuas)
resumen_grupos <- movies_analisis %>%
  group_by(Cluster) %>%
  summarise(
    Promedio_Popularidad = mean(popularity),
    Promedio_Votos_Avg = mean(voteAvg),
    Promedio_Duracion = mean(runtime),
    Promedio_Ingresos_Log = mean(revenue_log),
    Cant_Peliculas = n()
  )

knitr::kable(resumen_grupos, digits = 2, caption = "Perfil Promedio por Clúster")
```


## 3. Análisis de Componentes Principales (PCA)

### 3.1. Transformación de variables categóricas
**¿Es posible y vale la pena?**

Técnicamente es posible transformar variables categóricas utilizando variables *dummy* (0 y 1) sin embargo, en nuestro dataset de películas, estas variables presentan una alta cardinalidad al convertirlas, crearíamos una cantidad excesiva de columnas nuevas, generando un encuadre muy disperso que diluiría la varianza real que buscamos capturar por lo tanto, determinamos que **no vale la pena** incluirlas.


### 3.2. Conveniencia del Análisis (Matriz, KMO y Bartlett)

Primero, preparamos nuestras variables numéricas y calculamos las pruebas de factibilidad para asegurarnos de que el lienzo de datos es el adecuado.

```{r pca-pruebas, message=FALSE, warning=FALSE,echo=FALSE,results='hide'}
library(psych)
library(corrplot)
library(factoextra)

# Seleccionamos las variables numéricas limpias, evitando multicolinealidad perfecta
numericas_pca <- movies_clean %>%
  select(popularity, runtime, voteCount, voteAvg, actorsAmount, 
         genresAmount, productionCoAmount, productionCountriesAmount, 
         budget_log, revenue_log, mean_actor_popularity, max_actor_popularity, releaseYear) %>%
  na.omit()

# 1. Matriz de Correlación
matriz_cor <- cor(numericas_pca)
corrplot(matriz_cor, method = "color", type = "upper", tl.cex = 0.7)

# 2. Prueba de KMO
KMO(matriz_cor)

# 3. Test de Esfericidad de Bartlett
cortest.bartlett(matriz_cor, n = nrow(numericas_pca))
```

**Interpretación de los resultados y viabilidad:**

**Estudio de la Matriz de Correlación:** 
Al observar el gráfico, notamos inmediatamente "bloques" de color azul oscuro que nos indican fuertes correlaciones positivas. Destaca la altísima relación entre el presupuesto (`budget_log`) y los ingresos (`revenue_log`), los cuales a su vez están fuertemente ligados a la cantidad de votos (`voteCount`). También vemos una clara conexión entre la popularidad media y máxima de los actores.

* **Técnica de Análisis Factorial (KMO):** 
Obtuvimos un índice KMO general de **0.6**. Como este valor alcanza el umbral mínimo aceptable, concluimos que la proporción de varianza es adecuada y **sí es posible** utilizar la técnica de análisis factorial para hallar las componentes principales

* **Prueba de Esfericidad de Bartlett:** 
El valor p obtenido es **0** (prácticamente cero absoluto), el cual es muchísimo menor a 0.05. Esto nos permite rechazar con total seguridad la hipótesis nula de que la matriz es una matriz identidad, confirmando matemáticamente la fuerte multicolinealidad observada en la gráfica. En definitiva, **sí vale la pena** aplicar las componentes principales.

---

### 3.3. Ejecución del PCA e Interpretación

A continuación, estandarizamos los datos directamente en la función y ejecutamos el modelo para extraer nuestros componentes principales.

```{r pca-modelo,message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
# Ejecución del modelo PCA
pca_result <- prcomp(numericas_pca, center = TRUE, scale. = TRUE)

# Resumen de la variabilidad explicada
summary(pca_result)

# Gráfico de sedimentación
fviz_eig(pca_result, addlabels = TRUE, ylim = c(0, 50))

# Coeficientes principales (Loadings) de los primeros componentes
round(pca_result$rotation[, 1:4], 3)
```

**Selección de Componentes (Variabilidad):**

Al observar el gráfico de sedimentación (*Scree plot*), buscamos el punto donde la caída de la varianza crea un "codo" y comienza a estabilizarse. Vemos que el mayor aporte de información se da al inicio. Por lo tanto **seleccionaremos los primeros 4 componentes**. 
Tomamos esta decisión porque al sumar sus varianzas individuales estos 4 ejes logran explicar de forma acumulada el **57.2% de la variabilidad total** de nuestros datos, logrando un excelente equilibrio entre reducir la dimensionalidad y retener la información más valiosa de las películas.


**Interpretación de los Coeficientes Principales:**
Analizando la matriz de rotación y basándonos en las correlaciones previas, estos nuevos "ángulos" de nuestros datos se interpretan de la siguiente manera:

* **Componente 1 (Dim1 - Éxito Comercial e Inversión):** 

Este componente lidera con el 22.9% de la variabilidad y está fuertemente dibujado por las variables financieras (`budget_log`, `revenue_log`) y de interacción del público (`voteCount`). Nos habla directamente de la magnitud económica y el impacto comercial de la cinta.

* **Componente 2 (Dim2 - Poder Estelar del Elenco):**

Con un 14.7%, este eje captura casi en su totalidad el peso de las variables `mean_actor_popularity` y `max_actor_popularity`. Es un indicador claro y directo de qué tan famoso y reconocido es el talento involucrado en la producción.

* **Componentes 3 y 4 (Estructura de Producción):** 

Estos componentes recogen las varianzas secundarias relacionadas con la logística y el formato, balanceando variables como la cantidad total de actores en el reparto (`actorsAmount`), la duración de la película (`runtime`) y la cantidad de compañías productoras involucradas.
